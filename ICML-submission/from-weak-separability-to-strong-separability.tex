\section{From weak separability to strong separability}
\label{section:from-weak-separability-to-strong-separability}

In this section, we consider case when the examples are weakly linearly
separable. Throughout this section, we assume without loss of generality that
all examples lie in the unit ball $\B(0,1) \subseteq \R^d$.\footnote{Instead of
working with feature vector $x_t$ we can work with normalized feature vectors
$\widehat{x}_t = \frac{x_t}{\norm{x_t}}$. It can be easily checked that if
$(x_1,y_1), (x_2,y_2), \dots, (x_T,y_T)$ are weakly linearly separable with
margin $\gamma$ and $\norm{x_t} \le R$ for all $t$, then the normalized examples
$(\widehat{x}_1,y_1), \widehat{x}_2,y_2), \dots, (\widehat{x}_T,y_T)$ are weakly
linearly separable by margin $\gamma/R$.} Note that
Algorithm~\ref{algorithm:algorithm-for-strongly-linearly-separable-examples}
alone does not guarantee a finite mistake bound in this setting, as weak linear
separability does not imply strong linear separability.

We construct a positive definite kernel function $k(\cdot, \cdot)$ whose
corresponding feature map $\phi(\cdot)$ transforms any sequence of \emph{weakly}
linearly separable examples to \emph{strongly} linearly separable sequence of
examples. Specifically, $\phi$ has the property that if a set of labeled
examples in $\B(0,1)$ is weakly linearly separable with a margin $\gamma$, then
after applying $\phi$ the examples become strongly linearly separable with a
margin $\gamma'$ and their norms are bounded by $2$. The parameter $\gamma'$ is
a function of the old margin $\gamma$ and the number of classes $K$, and is
specified in \autoref{theorem:margin-transformation} below.

The kernel function $k:\B(0,1) \times \B(0,1) \to \R$ is defined as
$$
k(x,x') = \frac{1}{1 - \frac{1}{2}\ip{x}{x'}_{\R^d}} \; .
$$
Note that kernel function $k(x,x')$ can be evaluated in $O(d)$ time.

Consider the classical real separable Hilbert space $\ell_2 = \{ x \in \R^\infty
~:~ \sum_{i=1}^\infty x_i^2 < + \infty \}$ equipped with the standard inner
product $\ip{x}{x'}_{\ell_2} = \sum_{i=1}^\infty x_i x'_i$. If we index the
coordinates of $\ell_2$ by $d$-tuples $(\alpha_1, \alpha_2, \dots, \alpha_d)$ of
non-negative integers, the feature map that corresponds to $k$ is $\phi: \B(0,1)
\to \ell_2$,
\begin{align}
& \left(\phi(x_1, x_2, \dots, x_d)\right)_{(\alpha_1, \alpha_2, \dots, \alpha_d)} = x_1^{\alpha_1} x_2^{\alpha_2} \dots x_d^{\alpha_d} \nonumber \\
& \qquad \cdot \sqrt{2^{-(\alpha_1 + \alpha_2 + \dots + \alpha_d)} \binom{\alpha_1 + \alpha_2 + \dots + \alpha_d}{\alpha_1, \alpha_2, \dots, \alpha_d}}
\label{equation:phi}
\end{align}
where $\binom{\alpha_1 + \alpha_2 + \dots + \alpha_d}{\alpha_1, \alpha_2, \dots,
\alpha_d} = \frac{(\alpha_1 + \alpha_2 + \dots + \alpha_d)!}{\alpha_1! \alpha_2!
\dots \alpha_d!}$ is the multinomial coefficient. It can be easily checked that
$$
k(x,x') = \ip{\phi(x)}{\phi(x')}_{\ell_2}.
$$
The last equality together with the formula for $k$ implies that $k(x,x) <
+\infty$ for any $x$ in $\B(0,1)$ and thus in particular implies that $\phi(x)$
indeed lies in $\ell_2$.

The following theorem is our main technical result in this section. We defer its
proof to Section~\ref{section:margin-transformation}.

\begin{theorem}[Margin transformation]
\label{theorem:margin-transformation}
Let $(x_1, y_1)$, $(x_2, y_2)$, $\dots$, $(x_T, y_T)$ in $\B(0,1) \times
\{1,2,\dots,K\}$ be a sequence of labeled examples that is weakly linearly
separable with margin $\gamma > 0$. Let $\phi$ be as defined in
equation~\eqref{equation:phi} and let
\begingroup
\allowdisplaybreaks
\begin{align*}
r & = 2 \left\lceil \frac{1}{4} \log_2(4K-3) \right\rceil + 1, \quad \quad s = \left \lceil \log_2(2/\gamma) \right \rceil, \\
\gamma_1 & = \frac{1}{2\sqrt{K}}  \\
& \ \cdot \left(376 \lceil \log_2(2K-2) \rceil \cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil \right)^{-\frac{1}{2} \lceil \log_2(2K-2) \rceil \cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil}, \\
\gamma_2 & = \frac{2^{s(s+1)r(K-1)} }{4\sqrt{K}(2K-5/2) 2^{K-1}} \\
& \ \cdot \left(2^{2s+1} r(K-1) (4s+2)^2 \right)^{-(s+1/2)r(K-1)} \; .
\end{align*}
\endgroup
Then, the sequence of labeled examples transformed by $\phi$,
namely $(\phi(x_1), y_1), (\phi(x_2), y_2), \dots,
(\phi(x_T), y_T)$, is strongly linearly separable with margin $\gamma' =
\max\{\gamma_1, \gamma_2\}$. In addition, $\norm{\phi(x_1)}_{\ell_2},
\norm{\phi(x_2)}_{\ell_2}, \dots, \norm{\phi(x_T)}_{\ell_2} \le 2$.
\end{theorem}

Using this theorem we derive a mistake bound for
Algorithm~\ref{algorithm:kernelized} with kernel function $k(x,x') =
\ip{\phi(x)}{\phi(x')}_{\ell_2}$.

\begin{corollary}[Mistake upper bound]
\label{corollary:weakly-separable-examples-mistake-upper-bound}
Let $K$ be a positive integer and let $\gamma$ be a positive real number. If
$(x_1, y_1), (x_2, y_2), \dots, (x_T, y_T) \in \B(0,1) \times \{1,2,\dots,K\}$
is a sequence of weakly separable labeled examples with margin $\gamma > 0$,
then the expected number of mistakes made by Algorithm~\ref{algorithm:kernelized}
with kernel $k(x,x') = \frac{1}{1 - \frac{1}{2}\ip{x}{x'}_{\R^d}}$
is at most $2^{\widetilde{O}(\min(K \log^2 \frac{1}{\gamma},
\sqrt{\frac{1}{\gamma}} \log K))}$.
\end{corollary}

This corollary follows direcly from
Theorems~\ref{theorem:kernelized-upper-bound}
and~\ref{theorem:margin-transformation}.

\subsection{Proof of Theorem~\ref{theorem:margin-transformation}}
\label{section:margin-transformation}

\paragraph{Overview.} The idea behind construction and analysis of the mapping
$\phi$ is polynomial approximation. Specifically, we give $k$ polynomials $p_1$,
$\ldots$, $p_k$, such that:
\begin{align}
\label{equation:poly-pos}
& \forall t \in \cbr{1,2,\dots,T}, p_{y_t}(x_t) \ge \frac{\gamma'}2 \; ,
\\
\label{equation:poly-neg}
& \begin{gathered}
\forall t \in \cbr{1,2,\dots,T} \ \forall i \in \cbr{1,2,\ldots,K} \setminus \cbr{y_t} \\
p_i(x_t) \leq -\frac{\gamma'}2 \; .
\end{gathered}
\end{align}
As each polynomial $p_i$ can be written as $\ip{c_i}{\phi(x)}$ for some $c_i \in
\ell_2$, it immediately shows that the set of examples $(\phi(x_1),y_1), \ldots,
(\phi(x_T),y_T)$ is strongly linear separable.

To construct $p_1, p_2, \dots, p_k$ that satisfy
Equations~\eqref{equation:poly-pos} and~\eqref{equation:poly-neg}, we consider
constructing each $p_i$ separately. Specifically, $p_i$ needs to satisfy that:
\begin{align}
\label{equation:poly-pos-i}
\forall t \in \cbr{1,2,\dots,T}, y_t = i \Rightarrow p_i(y_t) \ge \frac{\gamma'}2 \; , \\
\label{equation:poly-neg-i}
\forall t \in \cbr{1,2,\dots,T}, y_t \neq i \Rightarrow p_i(y_t) \le -\frac{\gamma'}2 \; .
\end{align}

Under the weak linear separability assumption, we note that all examples from
class $i$ lie in
\[ R_i^+ = \bigcap_{j \in \cbr{1,\ldots,K} \setminus \cbr{i}} \cbr{x: \ip{w_i - w_j}{x} \geq \gamma}, \] and all examples from the remaining classes lie in
\[ R_i^- = \bigcup_{j \in \cbr{1,\ldots,K} \setminus \cbr{i}} \cbr{x: \ip{w_i - w_j}{x} \leq  -\gamma}. \]
Therefore, to satisfy Equations~\eqref{equation:poly-pos-i}
and~\eqref{equation:poly-neg-i}, it suffices to construct $p_i$ such that:
\begin{align*}
x \in R_i^+ & \Rightarrow p_i(x) \ge \frac {\gamma'} 2 \\
x \in R_i^- & \Rightarrow p_i(x) \le - \frac {\gamma'} 2
\end{align*}

According to the well known Stone-Weierstrass theorem (see
e.g.~\citet[Section~10.10]{Davidson-Donsig-2010}), on a compact set,
multivariate polynomials uniformly approximate any continuous function.
Intuitively speaking, we use a multivariate polynomial to approximate, on the
unit ball of $\R^d$, the indicator function corresponding to the intersection of
$m=K-1$ halfspaces. Within margin $\gamma$ along the decision boundary, we allow
the polynomial to attain arbitrary value. The polynomial separates examples in
one class from examples in the other classes. To be able to quantify $\gamma'$
we need to quantify certain parameters of the approximating polynomial. We
construct two different polynomials with different parameters. The parameters
are quantified in
Theorems~\ref{theorem:polynomial-approximation-1}~and~\ref{theorem:polynomial-approximation-2}
stated below.

Before we state the theorems, recall that a polynomial of $d$ variables is a
function $p:\R^d \to \R$ of the form
\begin{align*}
p(x)
& = p(x_1, x_2, \dots, x_d) \\
& = \sum_{\alpha_1, \alpha_2, \dots, \alpha_d} c_{\alpha_1, \alpha_2, \dots, \alpha_d} x_1^{\alpha_1} x_2^{\alpha_2} \dots x_d^{\alpha_d}
\end{align*}
where the sum ranges over a finite set of $d$-tuples $(\alpha_1, \alpha_2,
\dots, \alpha_d)$ of non-negative integers and $c_{\alpha_1, \alpha_2, \dots,
\alpha_d}$'s are real coefficients. The \emph{degree} of a polynomial $p$, denoted
by $\deg(p)$, is the largest value of $\alpha_1 + \alpha_2 + \dots + \alpha_d$
for which the coefficient $c_{\alpha_1, \alpha_2, \dots, \alpha_d}$ is non-zero.
Following the terminology of~\citet{Klivans-Servedio-2008},
the \emph{norm of a polynomial} $p$ is defined as
$$
\norm{p} = \sqrt{\sum_{\alpha_1, \alpha_2, \dots, \alpha_d} \left(c_{\alpha_1, \alpha_2, \dots, \alpha_d} \right)^2 } \; .
$$
It is easy see that this is indeed a norm, since we can interpret it as the
Euclidean norm of the vector of the coefficients of the polynomial.

\begin{theorem}[Polynomial approximation of intersection of halfspaces I]
\label{theorem:polynomial-approximation-1}
Let $v_1, v_2, \dots, v_m \in \R^d$ be vectors such that $\norm{v_1},
\norm{v_2}, \dots, \norm{v_m} \le 1$. Let $\gamma \in (0,1)$. There exists a
multivariate polynomial $p:\R^d \to \R$ such that
\begin{enumerate}
\item $p(x) \ge 1/2$ \\ for all $\displaystyle x \in \bigcap_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \ge \gamma \right\}$
\item $p(x) \le -1/2$ \\ for all $\displaystyle x \in \bigcup_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \le - \gamma \right\}$
\item $\displaystyle \deg(p) = \left\lceil \log_2(2m) \right\rceil \cdot \left\lceil \sqrt{\frac{1}{\gamma}} \right\rceil$
\item $\displaystyle \norm{p} \le \left( 188 \left\lceil \log_2(2m) \right\rceil \cdot \left\lceil \sqrt{\frac{1}{\gamma}} \right\rceil \right)^{\frac{1}{2} \left\lceil \log_2(2m) \right\rceil \cdot \left\lceil \sqrt{\frac{1}{\gamma}} \right\rceil}$
\end{enumerate}
\end{theorem}

\begin{theorem}[Polynomial approximation of intersection of halfspaces II]
\label{theorem:polynomial-approximation-2}
Let $v_1, v_2, \dots, v_m \in \R^d$ be vectors such that $\norm{v_1},
\norm{v_2}, \dots, \norm{v_m} \le 1$. Let $\gamma \in (0,1)$.
Define
$$
r = 2 \left\lceil \frac{1}{4} \log_2(4m + 1) \right\rceil + 1 \quad \text{and} \quad s = \left \lceil \log_2(1/\gamma) \right \rceil \; .
$$
Then, there exists a multivariate polynomial $p:\R^d \to \R$ such that
\begin{enumerate}
\item $\displaystyle p(x) \ge \frac{1}{4} \cdot 2^{s(s+1)rm}$ \\
for all $\displaystyle x \in \bigcap_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \ge \gamma \right\}$

\item $\displaystyle p(x) \le - \frac{1}{4} \cdot 2^{s(s+1)rm}$ \\
for all $\displaystyle x \in \bigcup_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \le - \gamma \right\}$

\item $\deg(p) \le (2s+1) rm$
\item $\norm{p} \le (2m-1/2) 2^m \cdot \left(2^{2s} rm (4s+2)^2 \right)^{(s+1/2)rm}$
\end{enumerate}
\end{theorem}

The proofs of the theorems can be found in
Section~\ref{section:proof-of-polynomial-approximation}. The geometric
interpretation of the two regions described in parts 1 and 2 of the theorems is
explained in Figure~\ref{figure:pizza-slice}. Similar but weaker results were
proved by~\citet{Klivans-Servedio-2008}. In particular, our bounds in parts 1,
2, 3, 4 of
Theorems~\ref{theorem:polynomial-approximation-1}~and~\ref{theorem:polynomial-approximation-2}
are independent of the dimension $d$.

\begin{figure}
\begin{center}
\input{figures/pizza-slice}
\end{center}
\caption[]{The figure shows the two regions used in parts 1 and 2 of
Theorems~\ref{theorem:polynomial-approximation-1}~and~\ref{theorem:polynomial-approximation-2}
for the case $m=d=2$ and a particular choice of vectors $v_1, v_2$ and margin
parameter $\gamma$. These regions are
$R^+ = \displaystyle \bigcap_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \ge \gamma \right\}$,
$R^- = \displaystyle \bigcup_{i=1}^m \left\{ x \in \R^d ~:~ \norm{x} \le 1, \ \ip{v_i}{x} \le - \gamma \right\}$
The separating hyperplanes $\ip{v_1}{x} = 0$ and $\ip{v_2}{x} = 0$ are shown as dashed lines.}
\label{figure:pizza-slice}
\end{figure}

The following lemma expresses any multivariate polynomial in $\R^d$
as a linear function in $\ell_2$ and gives an upper bound its the norm.

\begin{lemma}[Norm bound]
\label{lemma:norm-bound}
Let $p:\R^d \to \R$ be a multivariate polynomial.
There exists $c \in \ell_2$ such that $p(x) = \ip{c}{\phi(x)}_{\ell_2}$
and $\norm{c}_{\ell_2} \le 2^{\deg(p)/2} \norm{p}$.
\end{lemma}

\begin{proof}
Note that the polynomial $p$ can be written as
$p(x) = \sum_{\alpha_1, \alpha_2, \dots, \alpha_d} c'_{\alpha_1, \alpha_2, \dots, \alpha_d} x_1^{\alpha_1} x_2^{\alpha_2} \dots x_d^{\alpha_d}$.
We define $c \in \ell_2$ using the multi-index notation as
$$
c_{\alpha_1, \alpha_2, \dots, \alpha_d}
= \frac{c'_{\alpha_1, \alpha_2, \dots, \alpha_d} 2^{(\alpha_1 + \alpha_2 + \dots + \alpha_d)/2}}{\sqrt{\binom{\alpha_1 + \alpha_2 + \dots + \alpha_d}{\alpha_1, \alpha_2, \dots, \alpha_d}}}
$$
for all tuples $(\alpha_1, \alpha_2, \dots, \alpha_d)$ such that $\alpha_1 + \alpha_2 + \dots + \alpha_d \le \deg(p)$.
Otherwise, we define $c_{\alpha_1, \alpha_2, \dots, \alpha_d} = 0$. Clearly,
$\ip{c}{\phi(x)}_{\ell_2} = p(x)$.

Since
\begin{align*}
|c_{\alpha_1, \alpha_2, \dots, \alpha_d}|
& \le 2^{(\alpha_1 + \alpha_2 + \dots + \alpha_d)/2} |c'_{\alpha_1, \alpha_2, \dots, \alpha_d}| \\
& \le 2^{\deg(p)/2} |c'_{\alpha_1, \alpha_2, \dots, \alpha_d}| \; ,
\end{align*}
we have
\begin{align*}
\norm{c}_{\ell_2}
& \le 2^{\deg(p)/2} \sqrt{\sum_{\alpha_1, \alpha_2, \dots, \alpha_d} (c'_{\alpha_1, \alpha_2, \dots, \alpha_d})^2} \\
& = 2^{\deg(p)/2} \norm{p} \; . \qquad \qedhere
\end{align*}
\end{proof}

Using the lemma and the polynomial approximation theorems, we can prove the
mapping $\phi$ maps any a weakly separable data to a strongly separable data
set.

\begin{proof}[Proof of Theorem~\ref{theorem:margin-transformation}]
First osberve that for any $t=1,2,\dots,T$,
$$
\norm{\phi(x_t)}_{\ell_2} = k(x_t,x_t) = \frac{1}{1 - \frac{1}{2} \norm{x_t}^2} \le 2 \; .
$$

Since the examples $(x_1, y_1), (x_2, y_2), \dots, (x_T, y_T)$ are weakly
linearly separable with margin $\gamma$ there are vectors $w_1, w_2, \dots, w_K$
satisfying \eqref{equation:weak-linear-separability-1} anf
\eqref{equation:weak-linear-separability-2}.

Fix any $i \in \{1,2,\dots,K\}$. Consider the $K-1$ vectors $(w_i - w_j)/2$ for
$j \in \{1,2,\dots,K\} \setminus \{i\}$. Note that the vectors have norm at most
$1$.
Theorems~\ref{theorem:polynomial-approximation-1}~and~\ref{theorem:polynomial-approximation-2}
imply that there exists multivariate polynomials $p_i:\R^d \to \R$ and $q_i:\R^d
\to \R$ such that
\begin{align*}
\deg(p_i) & = \lceil \log_2(2K-2) \rceil \cdot \left\lceil \sqrt{\frac{2}{\gamma}} \right\rceil \; , \\
\deg(q_i) & = (2s+1) r(K-1) \; .
\end{align*}
Futhermore, for all $t=1,2,\dots,T$, if $y_t = i$ then $p_i(x_t) \ge 1/2$,
$q_i(x_t) \ge \frac{1}{4} \cdot 2^{s(s+1)r(K-1)}$ and if $y_t \neq i$ then
$p_i(x_t) \le -1/2$, $q_i(x) \le - \frac{1}{4} \cdot 2^{s(s+1)r(K-1)}$ and
\begin{align*}
\norm{p_i} & \le \left(188 \lceil \log_2(2K-2) \rceil \cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil \right)^{\frac{1}{2} \lceil \log_2(2K-2) \rceil
\cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil} \; , \\
\norm{q_i} & \le (2K-5/2) 2^{K-1} \\
& \qquad \cdot \left(2^{2s} r(K-1) (4s+2)^2 \right)^{(s+1/2)r(K-1)} \; .
\end{align*}
By \autoref{lemma:norm-bound} there exists $c_i, c_i' \in \ell_2$ such that
$\ip{c_i}{\phi(x)} = p_i(x)$ and $\ip{c_i'}{\phi(x)} = q_i(x)$ and
\begin{align*}
\norm{c_i}_{\ell_2}
& \le \left(376 \lceil \log_2(2K-2) \rceil \cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil \right)^{\frac{1}{2} \lceil \log_2(2K-2) \rceil
\cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil} \\
\norm{c'_i}_{\ell_2} & \le (2K-5/2) 2^{K-1} \\
& \qquad \cdot \left(2^{2s+1} r(K-1) (4s+2)^2 \right)^{(s+1/2)r(K-1)} \; .
\end{align*}
Define vectors $u_i, u_i' \in \ell_2$ as
\begin{align*}
u_i & = \frac{c_i}{\sqrt{K} \left(376 \lceil \log_2(2K-2) \rceil \cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil \right)^{\frac{1}{2} \lceil \log_2(2K-2) \rceil
\cdot \left \lceil \sqrt{\frac{2}{\gamma}} \right \rceil}} \; . \\
u_i' & = \frac{c_i'  \cdot \left(2^{2s+1} r(K-1) (4s+2)^2 \right)^{-(s+1/2)r(K-1)}}{\sqrt{K} (2K-5/2) 2^{K-1}} \; .
\end{align*}

Then, $\norm{u_1}^2 + \norm{u_2}^2 + \dots + \norm{u_K}^2 \le 1$ and
$\norm{u_1'}^2 + \norm{u_2'}^2 + \dots + \norm{u_K'}^2 \le 1$.
Futhermore, for all $t=1,2,\dots,T$, $\ip{u_{y_t}}{x_t} \ge \gamma_1$ and
$\ip{u'_{y_t}}{x_t} \ge \gamma_2$
and for all $j \in \{1,2,\dots,K\} \setminus \{y_t\}$,
$\ip{u_j}{x_t} \le - \gamma_1$ and $\ip{u'_j}{x_t} \le - \gamma_2$. In other words,
$(\phi(x_1), y_1), (\phi(x_2), y_2), \dots, (\phi(x_T), y_T)$ are
strongly linearly separable with margin $\gamma_1$ and also strongly linearly
separable with margin $\gamma_2$. Therefore, the examples are strongly
linearly separable with margin $\gamma' = \max\{\gamma_1, \gamma_2\}$.
\end{proof}
