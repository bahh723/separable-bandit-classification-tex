\section{Related work}
\label{section:related-work}

The problem of bandit multiclass linear classification was initially formulated
by the pioneering work of~\cite{Kakade-Shalev-Shwartz-Tewari-2008}. In that
work, two computationally inefficient algorithms that work in the standard
linearly separable setting are proposed: one with a mistake bound of $O(K^2 d
\ln(\frac{d}{\gamma^2}))$, the other with a mistake bound of
$\widetilde{O}(\frac{K^2}{\gamma^2} \ln T)$. In addition, the authors propose
the \textsc{Banditron} algorithm, a computationally efficient algorithm that has
a $O(T^{2/3})$ regret against the multiclass hinge loss
in the general setting, and has a $O(\sqrt{T})$ mistake
bound in the $\gamma$-weak linearly separable setting. The polynomial dependence
of \textsc{Banditron}'s mistake bound on the time horizon is undesirable for
problems with a long time horizon. One key open question left
by~\cite{Kakade-Shalev-Shwartz-Tewari-2008} is whether one can design
computationally efficient algorithms that achieve mistake bounds that match or
improve over those of inefficient algorithms. In this paper, we take a step
towards answering this question, showing that efficient algorithms with mistake
bounds quasipolynomial in the margin parameter can be obtained.

%Whether one can design an efficient algorithm with a finite mistake bound that
%has no dimensionality dependence is mentioned as an open problem in
%~\cite{Kakade-Shalev-Shwartz-Tewari-2008}, where in this paper we provide a
%positive answer. $O(k^2 d \ln(\frac{d}{\gamma^2}))$

Many works consider bandit multiclass classification in the general
non-separable setting. \cite{Abernethy-Rakhlin-2009} poses the open problem of
whether one can design an efficient algorithm to get a $O(\sqrt{T})$ regret
against some reasonable loss functions. \cite{Crammer-Gentile-2013} show that
such an algorithm can be obtained, provided that the distribution of
the label $y_t$ conditioned on feature vector $x_t$ satisfies certain parametric
noise assumption. \cite{Hazan-Kale-2011} developed the \textsc{Newtron}
algorithm, which has a regret between $O(\ln T)$ and $O(T^{2/3})$ against the
multiclass logistic loss, where the exact order of the regret depends on the
diameter of the benchmark class. In particular, if the diameter is $O(\ln T)$,
its regret bound would become $O(T^{2/3})$. The \textsc{SOBA} algorithm by
\cite{Beygelzimer-Orabona-Zhang-2017} achieves a regret of
$\widetilde{O}(\sqrt{T})$ against the
$\eta$-loss~\cite{Orabona-Cesa-Bianchi-Gentile-2012}. In addition, its regret
bound does not depend sensitively on the diameter of the benchmark class.
\cite{Foster-Kale-Luo-Mohri-Sridharan-2018} developed an algorithm that has a
regret of $\widetilde{O}(\sqrt{T})$ against the multiclass logistic loss, where
it doubly-exponentially improves over \cite{Hazan-Kale-2011}'s regret on its
dependence on the diameter of the benchmark class.

\cite{Chen-Lin-Lu-2014, Zhang-Jung-Tewari-2018} study online bandit multiclass
boosting under bandit feedback, where one can view online boosting as online
linear classification by treating each base hypothesis as a separate feature.
\cite{Chen-Lin-Lu-2014}'s online weak learning condition implies that
the set of examples is strongly separable by a convex combination of base hypotheses
with a margin. Under this condition, it gives an algorithm with a $O(T^{3/4})$
mistake bound. \cite{Zhang-Jung-Tewari-2018} considers an online weak learning
condition, which implies that all examples is separable by a convex combination of base hypotheses with a margin (See~\cite{Mukherjee-Schapire-2013}, Theorem 3).
Under this condition, it gives
a boosting algorithm with a $O(\sqrt{T})$ mistake bound with the knowledge of the edge
parameter. In addition, it gives an adaptive algorithm with a $O(T^{3/4})$
mistake bound.

The online bandit multiclass learning is a special case of the contextual bandits
problem~\cite{Auer-2003, Langford-Zhang-2008}, where the cost is the classification error.
A series of works in the contextual bandits learning literature focuses on
oracle-efficiency, that is, they assume access to an
oracle that given a set of cost-sensitve learning examples,

There has been much literature on the contextual bandit learning problem~\citep{Auer-2003, Langford-Zhang-2007}.
In this problem, the learner is given a policy class $\Pi$, and
at each timestep $t$, an example $x_t$ is shown, with an associated cost vector $c_t$ hidden.
The learner then takes an action $\hat{y}_t$, and observed the incurred cost $c_t$.
The goal of the learner is to minimize its regret $\sum_{t=1}^T c_t(\hat{y}_t) - \min_{\pi \in \Pi} \sum_{t=1}^T c_t(\pi(x_t))$.
The online bandit multiclass learning problem is a special case of the contextual bandits problem,
where the cost $c_t(i)$ is the classification error $I(i \neq y_t)$,
and the policy class $\Pi$ is the set of linear classifiers
$\cbr{x \mapsto \argmax_y (Wx)_y: W \in \R^{k \times d}}$.
A series of works in the contextual bandits learning literature focus on
oracle-efficiency~\citep{DudikHKKLRZ11, Monster:2014, RakhlinS16, Syrgkanis2016a, Syrgkanis2016b}.
Specifically, they assume access to a policy optimization
oracle that receives a set of cost-sensitive learning examples and policy class $\Pi$,
return the policy in $\Pi$ that minimizes its empirical cost on the examples, and the algorithm
only call the oracle a polynomial number of times.
However, these algorithms are not truly computationally efficient in our setting,
as it is NP-hard in general to find a linear classifier that minimizes the empirical cost over a set of examples~\citep{arora1997hardness}.

%as algorithms generate cost-sensitive examples that may not be linearly separable
%Algorithms that satisfy oracle efficiency has been proposed in the literature, for
%example.



Recently, \cite{Foster-Krishnamurthy-2018} developed a rich theory of contextual bandits
with surrogate losses, focusing on benchmarks of the form $\min_{f \in \calF}
\sum_{t=1}^T \frac{1}{K} \sum_{i=1}^K c_t(i) \phi( f_i(x_t) )$,
where $\calF$ contains score functions $f$
such that $\sum_{i=1}^K f_i(\cdot) \equiv 0$, and $\phi(s) = \max(1 - \frac s
\gamma, 0)$ or $\min(1, \max(1 - \frac s \gamma, 0))$. On one hand, it gives
information-theoretic mistake upper bounds under various settings of $\calF$,
including parametric and nonparametric classes. On the other hand, it gives
an efficient algorithm that has a $O(\sqrt{T})$ regret against the benchmark of
$\calF = \cbr{x \mapsto W x: W \in \R^{k \times d}, \one^T W = 0}$. A direct
application of this result to the online bandit multiclass learning problem
yields an algorithm with a $O(\sqrt{T})$ mistake bound in the strong
linearly separable setting.

%\cite{Chen-Chen-Zhang-Chen-Zhang-2009} studies the approach of reducing bandit
%multiclass learning to online binary classification using one-versus-all
%reduction. They show that

%Their results do not imply a finite mistake bound in the weakly separable
%setting, in that the benchmark loss can still be $\Omega(T)$.
